{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMchfyDVADEF/RKP9uKxHxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoKahl/gan_mnist/blob/main/GAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSCterJFqlFf"
      },
      "source": [
        "#Generative Adversial Network\n",
        "\n",
        "Fully-connected networks (generator and discriminator) as thew original implementation (2014)\n",
        "\n",
        "Example on the MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps4rJUDcri-c"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv9A0ug5qdzn"
      },
      "source": [
        "#Keras imports\n",
        "from keras.models import Sequential #Sequential model \n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "from keras.layers.advanced_activations import LeakyReLU #advanced LeakyRelu activation layer\n",
        "\n",
        "#Dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import numpy as np #import numpy library\n",
        "\n",
        "#Visualization \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQaLLwtfxN06"
      },
      "source": [
        "##Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rY8lY4xxMcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43412ccb-9a47-4dfd-8792-c7cbdfb0879c"
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() #load dataset\n",
        "\n",
        "#Normalization of the dataset\n",
        "X_train = (X_train.astype(np.float32) - 127.5) /127.5 #normaliza pixel values in the [-1,1] interval\n",
        "X_test = (X_test.astype(np.float32) - 127.5) /127.5 #normaliza pixel values in the [-1,1] interval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcxBH6o2yrNy",
        "outputId": "37d23f4d-6333-4735-b505-e5008d6782be"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsDW5Rkkzi3h"
      },
      "source": [
        "##Reshape input image into 1D array\n",
        "\n",
        "We need to feed the input to fully connected network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_H4h9drzTUg",
        "outputId": "59c5e2f1-b72c-435d-ba33-5fb1544a753b"
      },
      "source": [
        "#Save original dimension before reshaping\n",
        "\n",
        "num_Samples = X_train.shape[0]\n",
        "rows = X_train.shape[1]\n",
        "cols = X_train.shape[2]\n",
        "\n",
        "X_train = X_train.reshape(num_Samples, rows*cols)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN-MnB9m05Fn"
      },
      "source": [
        "##Models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFAb-zRo0_AU"
      },
      "source": [
        "###Network parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsGswTbh0zF9"
      },
      "source": [
        "gen_InputDim = 100 #Generator input dimension (like strating from the latent space)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9M3aUs1nBb"
      },
      "source": [
        "##Generator\n",
        "\n",
        "The generator architecture is like a decoder in the autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2is7dpM1061"
      },
      "source": [
        "generator = Sequential()\n",
        "\n",
        "generator.add(Dense(units=256, input_dim= gen_InputDim))\n",
        "generator.add(LeakyReLU(0.2)) #LeakyRealu with reduced alpha (slope of the negative segment) wrt default parameter\n",
        "\n",
        "generator.add(Dense(units=512))\n",
        "generator.add(LeakyReLU(0.2)) #LeakyRealu with reduced alpha (slope of the negative segment) wrt default parameter\n",
        "\n",
        "generator.add(Dense(units=1024))\n",
        "generator.add(LeakyReLU(0.2)) #LeakyRealu with reduced alpha (slope of the negative segment) wrt default parameter\n",
        "\n",
        "generator.add(Dense(units=X_train.shape[1], activation = 'tanh')) #tanh activation returns values in the [-1,1] interval\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHg1K2VU3jgA",
        "outputId": "a7b3167c-1f85-498f-eec4-a2d1d1b17449"
      },
      "source": [
        "generator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "generator.summary()\n",
        "#plot_model(generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               25856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 784)               803600    \n",
            "=================================================================\n",
            "Total params: 1,486,352\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LMN7hVQ4UYJ"
      },
      "source": [
        "##Discriminator \n",
        "\n",
        "The discriminator is an image classifier. The output is binary: 1(true) for original image nd 0 for fakes (generated by the generator)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX4GMz9H4kpq"
      },
      "source": [
        "discriminator = Sequential() #Sequential model\n",
        "\n",
        "discriminator.add(Dense(units=1024, input_dim=generator.output_shape[1]))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "\n",
        "discriminator.add(Dense(units=512))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "\n",
        "discriminator.add(Dense(units=256))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "discriminator.add(Dense(units=1, activation='sigmoid')) #1 output unit for binary classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XQLhKvAQ19A",
        "outputId": "dc0c696f-bfa5-4416-8736-27b61ab8cbfc"
      },
      "source": [
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 1,460,225\n",
            "Trainable params: 1,460,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5gxicNRdgm"
      },
      "source": [
        "##Gan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndyztEy2RKQr",
        "outputId": "cedaec7c-abe8-49d4-e460-fa1f723795e7"
      },
      "source": [
        "gan = Sequential()\n",
        "\n",
        "gan.add(generator)\n",
        "gan.add(discriminator)\n",
        "\n",
        "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "gan.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 784)               1486352   \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 1)                 1460225   \n",
            "=================================================================\n",
            "Total params: 2,946,577\n",
            "Trainable params: 2,946,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYgUEIgiSBvl"
      },
      "source": [
        "##Training\n",
        "\n",
        "The training is the hardest part for Gans.\n",
        "\n",
        "The process is very parameter dependent and notoriously difficult to tune.\n",
        "The training process itself is articulated as it requires alternate training of the generator and the discriminator to allow for strong models to be trained.\n",
        "The discriminator will be trained separately on batches of real and fake images (from the generator).\n",
        "Training of the generator will require to attach it to the discriminator (as we have nothing for judging the output of the generator). The fake images will be fed to the discriminator and the only way to improve for the generator will be to see if the fake images are able to fool the discriminator (ideal objective would be to have discriminator accuracy = 0.5). **Please note that we will need to freese the discriminator's weights when we train the generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DDljjRD7v8u"
      },
      "source": [
        "#Define a function for visualizing the images that the generator is able to generate\r\n",
        "\r\n",
        "def plot_generated_images(epoch, gen, numSamples=100, inputDim, dim=(10,10), figureSize(10,10)):\r\n",
        "  #epoch: epoch number\r\n",
        "  #gen: instance of the generator to use for generating the images\r\n",
        "  #numSamples: number of images to be generated\r\n",
        "  #inputDim: dimension of the input vectors\r\n",
        "  #dim: size in pixels of each image in the figure\r\n",
        "  #figureSize: size in inches of the whole figure\r\n",
        "\r\n",
        "  noise = np.random.normal(loc=0, scale=1, size=[numSamples, inputDim]) #generate random input vectors. Each of them has gen_InputDim dimensions. Each vector is like a \"noisy\" zero vector with 100 components.\r\n",
        "  gen_images = gen.predict(noise) #images produced by the generator\r\n",
        "\r\n",
        "  gen_images = gen_images.reshape(numSamples, rows, cols) #reshape images produced by the generator to their 2D aspect\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUAO7V7HR0II"
      },
      "source": [
        "#Defining a function for all training instructions\n",
        "\n",
        "def training(epochs=1, batch_size=128):\n",
        "  batch_count = int(num_Samples / batch_size) #number of batches\n",
        "\n",
        "  for e in range (1, epochs+1): #epochs counter starts from 1\n",
        "    print('Epochs: ', e)\n",
        "    for _ in range (batch_count):\n",
        "      #generate input vectors from the generator\n",
        "      noise = np.random.normal(loc=0, scale=1, size=[batch_size, gen_InputDim]) #generate random input vestors. Each of them has gen_InputDim dimensions.\n",
        "\n",
        "      #generate fake images batch by feeding vectors to the generator\n",
        "      generated_images = generator.predict(noise) #the generator produces an image for each input vector\n",
        "\n",
        "      #generate batch of real images from dataset\n",
        "      dataset_batch = X_train[np.random.randint(low=0, high=X_train.shape[0], size=batch_size)]\n",
        "\n",
        "      #compose together fake and real images in a single batch\n",
        "      X_batch = np.concatenate([dataset_batch, generated_images])\n",
        "\n",
        "      #create label vectors\n",
        "      Y_batch = np.zeros(batch_size*2) #create a zero vector with batch_size*2 components\n",
        "\n",
        "      #TRAIN discriminator\n",
        "      discriminator.trainable = True #set training flag to True to allow modification of weights in the training process\n",
        "      discriminator.train_on_batch(X_batch, Y_batch) #train_on_batch trains the model on a given batch.\n",
        "\n",
        "      #TRAIN generator (by training on the whole gan model)\n",
        "      noise = np.random.normal(loc=0, scale=1, size=[batch_size, gen_InputDim]) #generate random input vectors. Each of them has gen_InputDim dimensions.\n",
        "      Y_noise = np.ones(batch_size) #label \"1\" for the fake images in order to \"trick\" the discriminator and get the distance between the label and the discriminator's output\n",
        "      discriminator.trainable = False #training flag to false to disable weight modification to the discriminator\n",
        "      gan.train_on_batch(noise, Y_noise) #train the gan with discriminator wieghts frozen\n",
        "    \n",
        "    if e==1 or e%10==0: #every 10 eppochs (+ the first one)\n",
        "      plot_generated_images(e, generator) #generate new images"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}